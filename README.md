Ná»™i dung mÃ´n há»c
1. TÃ¬m kiáº¿m trong khÃ´ng gian tráº¡ng thÃ¡i

Sinh viÃªn Ä‘Æ°á»£c tiáº¿p cáº­n cÃ¡c khÃ¡i niá»‡m ná»n táº£ng:

ğŸ”¹ 8-Puzzle

MÃ´ hÃ¬nh hÃ³a tráº¡ng thÃ¡i, hÃ nh Ä‘á»™ng vÃ  mÃ´ hÃ¬nh chuyá»ƒn tiáº¿p

Thuáº­t toÃ¡n Ä‘Æ°á»£c cÃ i Ä‘áº·t:

Breadth-First Search (BFS)

A* Search (Manhattan, Euclidean heuristic)

PhÃ¢n tÃ­ch: admissibility, consistency cá»§a heuristic

Thá»­ nghiá»‡m 1000 tráº¡ng thÃ¡i ngáº«u nhiÃªn vÃ  so sÃ¡nh hiá»‡u suáº¥t thuáº­t toÃ¡n

ğŸ”¹ Pacman Search

MÃ´ hÃ¬nh hoÃ¡ báº£n Ä‘á»“, vá»‹ trÃ­ Pacman, thá»©c Äƒn vÃ  váº­t cáº£n

Thuáº­t toÃ¡n sá»­ dá»¥ng:

Uniform-Cost Search (UCS)

A* Search (Manhattan, Euclidean)

Má»¥c tiÃªu: Äƒn táº¥t cáº£ thá»©c Äƒn vÃ  Ä‘i qua 4 gÃ³c

Triá»ƒn khai bá»™ sinh káº¿ thá»«a tráº¡ng thÃ¡i, kiá»ƒm tra má»¥c tiÃªu, tÃ­nh chi phÃ­

2. Local Search Algorithms

BÃ i trÃ¬nh bÃ y táº­p trung vÃ o ba thuáº­t toÃ¡n tÃ¬m kiáº¿m cá»¥c bá»™:

ğŸ”¹ Random Restart Hill-Climbing

TrÃ¡nh káº¹t á»Ÿ cá»±c trá»‹ Ä‘á»‹a phÆ°Æ¡ng

Cháº¡y nhiá»u láº§n vÃ  chá»n lá»i giáº£i tá»‘t nháº¥t

ğŸ”¹ Simulated Annealing

Cho phÃ©p â€œnháº£yâ€ ra khá»i local optimum nhá» xÃ¡c suáº¥t Boltzmann

Biáº¿n thiÃªn nhiá»‡t Ä‘á»™ theo schedule

ğŸ”¹ Local Beam Search

Duy trÃ¬ k tráº¡ng thÃ¡i tá»‘t nháº¥t má»—i vÃ²ng

Táº­p trung khai thÃ¡c cÃ¡c á»©ng viÃªn tiá»m nÄƒng

CÃ¡c thuáº­t toÃ¡n Ä‘Æ°á»£c Ã¡p dá»¥ng Ä‘á»ƒ tÃ¬m Ä‘iá»ƒm cá»±c Ä‘áº¡i trÃªn áº£nh Ä‘Æ°á»£c Ã¡nh xáº¡ thÃ nh evaluation surface.

3. Logic vÃ  RÃ ng buá»™c â€“ N-Queens vá»›i CNFs

NhÃ³m triá»ƒn khai bÃ i toÃ¡n Ä‘áº·t N quÃ¢n háº­u thÃ´ng qua:

Biáº¿n hÃ³a tá»«ng Ã´ thÃ nh biáº¿n logic

Thiáº¿t láº­p rÃ ng buá»™c:

1 háº­u má»—i hÃ ng

1 háº­u má»—i cá»™t

KhÃ´ng trÃ¹ng Ä‘Æ°á»ng chÃ©o chÃ­nh/phá»¥

Chuyá»ƒn Ä‘á»•i cÃ´ng thá»©c sang Conjunctive Normal Form (CNF)

Giáº£i báº±ng Glucose3 SAT Solver

In láº¡i bÃ n cá» lá»i giáº£i dÆ°á»›i dáº¡ng ma tráº­n

4. Minimax & Alpha-Beta â€“ 8x8 Tic-Tac-Toe

XÃ¢y dá»±ng trÃ² chÆ¡i Tic-Tac-Toe má»Ÿ rá»™ng:

Báº£ng 8Ã—8, tháº¯ng khi liÃªn tiáº¿p 4 quÃ¢n

NgÆ°á»i chÆ¡i Ä‘áº¥u vá»›i mÃ¡y

MÃ¡y sá»­ dá»¥ng:

Minimax + Alpha-Beta Pruning

HÃ m Ä‘Ã¡nh giÃ¡ (Evaluate):

Chiáº¿n lÆ°á»£c táº¥n cÃ´ng: táº¡o chuá»—i 1/2/3

Chiáº¿n lÆ°á»£c phÃ²ng thá»§: cháº·n chuá»—i Ä‘á»‘i thá»§

Äiá»ƒm Æ°u tiÃªn theo vÃ¹ng trÃªn báº£ng (center control)

5. Machine Learning â€“ Decision Tree

Vá»›i táº­p dá»¯ liá»‡u gá»“m Rank vÃ  cÃ¡c Ä‘iá»ƒm Q1â€“Q9:

ğŸ”¹ Pháº§n 1: TÃ­nh toÃ¡n thÃ´ng tin

Entropy

Average Entropy

Information Gain
â†’ Chá»n thuá»™c tÃ­nh tá»‘t nháº¥t cho root node

ğŸ”¹ Pháº§n 2: CÃ¢y quyáº¿t Ä‘á»‹nh (Decision Tree â€“ Scikit-learn)

TÃ¡ch dá»¯ liá»‡u train/test

Huáº¥n luyá»‡n mÃ´ hÃ¬nh Ä‘á»™ sÃ¢u tá»‘i Æ°u

ÄÃ¡nh giÃ¡ báº±ng:

Accuracy

Confusion Matrix

Feature Importance

Trá»±c quan hÃ³a cÃ¢y quyáº¿t Ä‘á»‹nh

ğŸ“˜ CÃ¡c ká»¹ thuáº­t & thÆ° viá»‡n sá»­ dá»¥ng

Python, NumPy, Pandas, Matplotlib,
Scikit-learn, Glucose3 (SAT Solver),
thuáº­t toÃ¡n tÃ¬m kiáº¿m cá»• Ä‘iá»ƒn & heuristic AI.

ğŸ‘¥ ThÃ nh viÃªn thá»±c hiá»‡n

LÃ½ Tuáº¥n An â€“ 52000620

LÃ½ Tiá»ƒu Long â€“ 52200168

Giáº£n HoÃ ng Huy â€“ 52200147

Huá»³nh HoÃ i Nam â€“ 52200151

LÃª Há»“ng Quang â€“ 52200156
